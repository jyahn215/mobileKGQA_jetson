{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'webqsp'\n",
    "split = 'train'\n",
    "\n",
    "\n",
    "with open(f\"./../data/preprocessed_data/{dataset_name}/_domains/total/gpt_labeled_{dataset_name}_raw_{split}.jsonl\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from strings to tuples of triplets\n",
    "def get_tuples(input):\n",
    "    trunc_cnt = 0\n",
    "    pattern = r'(.*?)(,.*?\\..*?\\..*?,)(.*)'\n",
    "\n",
    "    output_evi = []\n",
    "    for evi in input:\n",
    "        match = re.search(pattern, evi)\n",
    "        if match is None or match.lastindex < 3:\n",
    "            trunc_cnt += 1\n",
    "        else:\n",
    "            output_evi.append((match.group(1).replace('(', '').strip(), match.group(2)[1:-1].strip(), match.group(3).replace(')', '').strip()))\n",
    "    return output_evi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_exist_cnt = 0\n",
    "total_cnt = 0\n",
    "pattern = r'(.*?)(,.*?\\..*?\\..*?,)(.*)'\n",
    "num_evi = []\n",
    "for idx, each in enumerate(tqdm(data)):\n",
    "    input_evi = each['user_query'].split('Question')[0].split('\\n')[1:-2]\n",
    "    input_evi = get_tuples(input_evi)\n",
    "\n",
    "    output = each['response'].split('\\n')\n",
    "    output = [evi for evi in output if 'evidence:' in evi]\n",
    "    output = [evi[evi.find('evidence:') + len('evidence:') + 1 :].strip() for evi in output]\n",
    "\n",
    "    output_evi = get_tuples(output)\n",
    "    good_evi = []\n",
    "    for each_evi in output_evi:\n",
    "        total_cnt += 1\n",
    "\n",
    "        # two directions both count. in some cases, gpt will correct the order\n",
    "        if (each_evi in input_evi or tuple(reversed(each_evi)) in input_evi):\n",
    "            good_evi.append(each_evi)\n",
    "        else:\n",
    "            non_exist_cnt += 1\n",
    "            # if non_exist_cnt == 100:\n",
    "                # raise ValueError(f'{each_evi} not in {input_evi}')\n",
    "\n",
    "    data[idx]['gpt_labeled_evi'] = good_evi\n",
    "    num_evi.append(len(output_evi))\n",
    "\n",
    "print(non_exist_cnt, total_cnt, non_exist_cnt / total_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for samples GPT provides more than 20 evidences, perhaps remove them\n",
    "for idx, each in enumerate(tqdm(data)):\n",
    "    if len(data[idx]['gpt_labeled_evi']) > 20:\n",
    "        data[idx]['gpt_labeled_evi'] = []\n",
    "fig = plt.hist(num_evi, bins=range(0, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count coverage of samples that GPT provides valid evidences\n",
    "cnt = 0\n",
    "for each in data:\n",
    "    if len(each['gpt_labeled_evi']) > 0:\n",
    "        cnt += 1\n",
    "print(cnt, len(data), cnt / len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "\n",
    "for each in data:\n",
    "    if len(each['gpt_labeled_evi']) > 0:\n",
    "        if \"triples\" in each:\n",
    "            res[each['triples']] = each['gpt_labeled_evi']\n",
    "        elif \"qid\" in each:\n",
    "            res[each['qid']] = each['gpt_labeled_evi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(res, f'./../data/preprocessed_data/{dataset_name}/_domains/total/gpt_labeled_{dataset_name}_cleaned_{split}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EMNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
